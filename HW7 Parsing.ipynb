{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a8c8485",
   "metadata": {},
   "source": [
    "### Урок 7. Парсинг данных. Selenium в Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde954d3",
   "metadata": {},
   "source": [
    "### 1) Взять любую категорию товаров на сайте Леруа Мерлен. Собрать следующие данные:\n",
    "● название;\n",
    "● все фото;\n",
    "● ссылка;\n",
    "● цена.\n",
    "\n",
    "Реализуйте очистку и преобразование данных с помощью ItemLoader. Цены должны быть в виде числового значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331646bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.http import HtmlResponse\n",
    "from leroyparser.items import LeroyparserItem\n",
    "from scrapy.loader import ItemLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7982f1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeroymerlinSpider(scrapy.Spider):\n",
    "    name = 'leroymerlin'\n",
    "    allowed_domains = ['leroymerlin.ru']\n",
    "\n",
    "    def __init__(self, text):\n",
    "        self.start_urls = [f'https://leroymerlin.ru/search/?q={text}']\n",
    "\n",
    "    def parse(self, response: HtmlResponse):\n",
    "        links_on_product = response.xpath(\"//div[@class='hover-image-buttons']/a/@href\").extract()\n",
    "        for link in links_on_product:\n",
    "            if 'product' in link:\n",
    "                yield response.follow(link, callback=self.parse_product)\n",
    "\n",
    "        next_page = response.xpath(\"//div[@class='next-paginator-button-wrapper']/a/@href\").extract_first()\n",
    "        yield response.follow(next_page, callback=self.parse)\n",
    "\n",
    "    def parse_product(self, response: HtmlResponse):\n",
    "        loader = ItemLoader(item=LeroyparserItem(), response=response)\n",
    "\n",
    "        loader.add_value('_id', str(response))\n",
    "        loader.add_xpath('name', \"//h1/text()\")\n",
    "        loader.add_xpath('photos', \"//source[@media=' only screen and (min-width: 1024px)']/@srcset\")\n",
    "        loader.add_xpath('terms', \"//dt/text()\")\n",
    "        loader.add_xpath('definitions', \"//dd/text()\")\n",
    "        loader.add_xpath('price', \"//meta[@itemprop='price']/@content\")\n",
    "        loader.add_value('link', str(response))\n",
    "\n",
    "        yield loader.load_item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773836b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "import re\n",
    "from scrapy.loader.processors import TakeFirst, MapCompose, Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45679d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(values):\n",
    "    pattern = re.compile('(\\d+)\\/')\n",
    "    values = int(re.findall(pattern, values)[0])\n",
    "    return values\n",
    "\n",
    "\n",
    "def get_link(values):\n",
    "    pattern = re.compile('<\\d+ (.+)>')\n",
    "    values = re.findall(pattern, values)\n",
    "    return values\n",
    "\n",
    "\n",
    "def edit_definitions(values):\n",
    "    pattern = re.compile('\\\\n +')\n",
    "    values = re.sub(pattern, '', values)\n",
    "    try:\n",
    "        return float(values)\n",
    "    except ValueError:\n",
    "        return values\n",
    "\n",
    "\n",
    "def change_price(values):\n",
    "    values = float(values)\n",
    "    return values\n",
    "\n",
    "\n",
    "class LeroyparserItem(scrapy.Item):\n",
    "    _id = scrapy.Field(input_processor=MapCompose(get_id))\n",
    "    name = scrapy.Field(output_processor=TakeFirst())\n",
    "    photos = scrapy.Field(input_processor=MapCompose())\n",
    "    terms = scrapy.Field(input_processor=MapCompose())\n",
    "    definitions = scrapy.Field(input_processor=MapCompose(edit_definitions))\n",
    "    price = scrapy.Field(input_processor=MapCompose(change_price))\n",
    "    characteristic = scrapy.Field()\n",
    "    link = scrapy.Field(output_processor=MapCompose(get_link))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
